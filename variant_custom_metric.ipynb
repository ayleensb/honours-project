{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20f72445-9bfa-4fd5-b2d8-57e79d6a61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datasets\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.datasets import CompasDataset\n",
    "#import fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4bb2b-1b23-4ed3-9bfa-58f4cf2639f5",
   "metadata": {},
   "source": [
    "#### Variant of new metric:\n",
    "\n",
    "- bi ranges 0,1,-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bbdf0f1b-3780-4598-95c9-4f42e53e959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_new_metric(arr_pred, arr_true, arr_grp):\n",
    "    grp_priv = [[], []]\n",
    "    grp_unpriv = [[], []]\n",
    "\n",
    "    #j is the number of unique groups in arr_grp - an implicit parameter.\n",
    "    j = len(set(arr_grp))\n",
    "    #print(\"total number of unique groups: \", j)\n",
    "\n",
    "    for i, label in enumerate(arr_grp):\n",
    "        #for privileged class\n",
    "        if label == 1.0:\n",
    "            #add the corresponding prediction + gt label for that class using the index associated with that label\n",
    "            grp_priv[0].append(arr_pred[i])\n",
    "            grp_priv[1].append(arr_true[i])\n",
    "        \n",
    "        #for unprivileged class \n",
    "        else:\n",
    "            grp_unpriv[0].append(arr_pred[i])\n",
    "            grp_unpriv[1].append(arr_true[i])\n",
    "    \n",
    "    #print(\"Privileged group: \", grp_priv)\n",
    "    #print(\"Unprivileged group: \", grp_unpriv)\n",
    "    \n",
    "    priv_indiv_bi = [] #stores individual benefit value of each instance\n",
    "    priv_grp_bi = 0 #tracks total benefit for group\n",
    "    \n",
    "    #1. for each index in a group calculate the benefit, bi\n",
    "    for pred, gt in zip(grp_priv[0], grp_priv[1]):\n",
    "        #calculate benefit for each instance in a group with new range, 0,1,-1 \n",
    "        indiv_benefit = (int(pred) - int(gt)) \n",
    "        \n",
    "        #2. Sum the total benefit of each group\n",
    "        priv_grp_bi += indiv_benefit\n",
    "        \n",
    "        #3. divide by size of group which is total number of instances in each group.\n",
    "        priv_av_bi = priv_grp_bi / len(grp_priv[0]) #[0] has predictions which will give that number.\n",
    "\n",
    "        #store individual benefit of each instance in a list\n",
    "        priv_indiv_bi.append(indiv_benefit)\n",
    "        \n",
    "    #print(\"all bi scores for privileged instances:\\n\", priv_indiv_bi)\n",
    "    #print(priv_grp_bi)\n",
    "    #print(priv_av_bi)\n",
    "\n",
    "    unpriv_indiv_bi = []\n",
    "    unpriv_grp_bi = 0\n",
    "    for pred, gt in zip(grp_unpriv[0], grp_unpriv[1]):\n",
    "        indiv_benefit = (int(pred) - int(gt))  \n",
    "        unpriv_grp_bi += indiv_benefit\n",
    "        unpriv_av_bi = unpriv_grp_bi / len(grp_priv[0])\n",
    "        unpriv_indiv_bi.append(indiv_benefit)\n",
    "\n",
    "    #print(\"\\nall bi scores for unprivileged instances:\\n\", unpriv_indiv_bi)\n",
    "    #print(unpriv_grp_bi)\n",
    "    #print(unpriv_av_bi)\n",
    "   \n",
    "    #4. division result is divided by the sum of g1 and g2 - J\n",
    "    result = int(priv_av_bi + unpriv_av_bi) / j\n",
    "\n",
    "    #print(\"new metric value: \", result)\n",
    "    #return  priv_av_bi, unpriv_av_bi to see individual benefit for each group type\n",
    "    return result\n",
    "\n",
    "#var_new_metric(predictions, ground_truth, grp_membership)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d2fee3b-1702-45aa-b495-7f0fae8fb1ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group membership array:  [0 0 0 0 0 0 0 0 1 1]\n",
      "group membership with desc feature:  [1 1 1 1 1 1 1 1 0 0]\n",
      "metric score for fixed arrays:  -0.5\n",
      "metric score for fixed arrays with group desc flag:  0.5\n",
      "metric score for randomised arrays:  -0.5\n"
     ]
    }
   ],
   "source": [
    "#function to generate arrays synthetically by using fixed distributions:\n",
    "\n",
    "#function takes in the size of array and the type of distribution to generate\n",
    "#also takes as input the order for correct 0s and 1s placement.\n",
    "def gen_fixed_dist_combinations(num_of_instances, \n",
    "                                grp_dist, true_dist, pred_dist, \n",
    "                                grp_order='asc', true_order='asc', pred_order='asc',\n",
    "                                randomise=False):\n",
    "    \n",
    "    #a dictionary that stores the types of expected distributions and maps to their corresp probabilties\n",
    "    distribution_mapping = {\"50/50\": (0.5, 0.5), #50% 0s 50% 1s\n",
    "                            \"80/20\": (0.8, 0.2), #80% 0s 20% 1s\n",
    "                            \"90/10\": (0.9, 0.1), #90% 0s 10% 1s\n",
    "                            \"20/80\": (0.2, 0.8), #20% 0s 80% 1s\n",
    "                            \"10/90\":(0.1, 0.9)} #10% 0s 90% 1s\n",
    "\n",
    "    #get the given parameters of probabilties for each distribution from the dict\n",
    "    group_probability = distribution_mapping.get(grp_dist)\n",
    "    gt_probability = distribution_mapping.get(true_dist)\n",
    "    pred_probability = distribution_mapping.get(pred_dist)\n",
    "\n",
    "    if randomise:\n",
    "        arr_grp = np.random.choice([0,1], size=num_of_instances, p=group_probability)\n",
    "        arr_true = np.random.choice([0,1], size=num_of_instances, p=gt_probability)\n",
    "        arr_pred = np.random.choice([0,1], size=num_of_instances, p=pred_probability)\n",
    "\n",
    "    else:\n",
    "        #calculations for fixing the 0s and 1s for each array using probabilities and array size\n",
    "        group_zeroes =  int(num_of_instances * group_probability[0])\n",
    "        group_ones =  num_of_instances - group_zeroes\n",
    "    \n",
    "        true_zeroes = int(num_of_instances * gt_probability[0])\n",
    "        true_ones = num_of_instances - true_zeroes\n",
    "    \n",
    "        pred_zeroes = int(num_of_instances * pred_probability[0])\n",
    "        pred_ones = num_of_instances - pred_zeroes\n",
    "\n",
    "        #create predictions array based on desired order of 0s and 1s.\n",
    "        if pred_order == 'asc':\n",
    "            arr_pred = np.array([0] * pred_zeroes + [1] * pred_ones)\n",
    "        elif pred_order == 'desc':\n",
    "            arr_pred = np.array([1] * pred_zeroes + [0] * pred_ones)\n",
    "        else:\n",
    "            raise ValueError(\"prediction array order must be 'asc' or 'desc'\")\n",
    "    \n",
    "        #create ground truth labels array based on desired order of 0s and 1s.\n",
    "        if true_order == 'asc':\n",
    "            arr_true = np.array([0] * true_zeroes + [1] * true_ones)\n",
    "        elif true_order == 'desc':\n",
    "            arr_true = np.array([1] * true_zeroes + [0] * true_ones)\n",
    "        else:\n",
    "            raise ValueError(\"prediction array order must be 'asc' or 'desc'\")\n",
    "    \n",
    "        #create group memberships array based on desired order of 0s and 1s.\n",
    "        if grp_order == 'asc':\n",
    "            arr_grp = np.array([0] * group_zeroes + [1] * group_ones)\n",
    "        elif grp_order == 'desc':\n",
    "            arr_grp = np.array([1] * group_zeroes + [0] * group_ones)\n",
    "        else:\n",
    "            raise ValueError(\"group membership array order must be 'asc' or 'desc'\")\n",
    "    \n",
    "    return arr_grp, arr_true, arr_pred  \n",
    "\n",
    "\n",
    "\n",
    "arr_grp, arr_true, arr_pred = gen_fixed_dist_combinations(10, \n",
    "                                                          \"80/20\", \n",
    "                                                          \"50/50\", \n",
    "                                                          \"80/20\", \n",
    "                                                          grp_order='asc',\n",
    "                                                          true_order='asc', \n",
    "                                                          pred_order='asc', \n",
    "                                                          randomise=False)\n",
    "\n",
    "arr_grp_desc, arr_true_asc, arr_pred_asc = gen_fixed_dist_combinations(10, \n",
    "                                                          \"80/20\", \n",
    "                                                          \"50/50\", \n",
    "                                                          \"80/20\",\n",
    "                                                        grp_order='desc',\n",
    "                                                        true_order='asc',\n",
    "                                                        pred_order='asc', \n",
    "                                                        randomise=False)\n",
    "\n",
    "arr_grp_rand, arr_true_rand, arr_pred_rand = gen_fixed_dist_combinations(10, \n",
    "                                                          \"80/20\", \n",
    "                                                          \"50/50\", \n",
    "                                                          \"80/20\", \n",
    "                                                          randomise=True)\n",
    "\n",
    "print(\"group membership array: \", arr_grp)\n",
    "# print(\"predictions array: \", arr_pred)\n",
    "# print(\"grount truth labels array: \", arr_true)\n",
    "\n",
    "\n",
    "# #to check if that ordering feature even does anything\n",
    "print(\"group membership with desc feature: \", arr_grp_desc)\n",
    "# print(\"predictions with asc feature: \", arr_pred_asc)\n",
    "# print(\"grount truth labels with asc feature: \", arr_true_asc)\n",
    "\n",
    "# print(\"group membership with randomness: \", arr_grp_rand)\n",
    "# print(\"predictions with randomness: \", arr_pred_rand)\n",
    "# print(\"grount truth labels with randomness: \", arr_true_rand)\n",
    "\n",
    "\n",
    "#checking to see if the desc/asc feature changes the score for the metric:\n",
    "print(\"metric score for fixed arrays: \", new_metric(arr_grp, arr_true, arr_pred))\n",
    "print(\"metric score for fixed arrays with group desc flag: \", new_metric(arr_grp_desc, arr_true_asc, arr_pred_asc))\n",
    "print(\"metric score for randomised arrays: \",new_metric(arr_grp_rand, arr_true_rand, arr_pred_rand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9e8ac14-cd2e-4ec1-be78-e9db669fbf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def balanced_accuracy(arr_true, arr_pred):\n",
    "    y_true = arr_true\n",
    "    y_pred = arr_pred\n",
    "    return balanced_accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a6460ba5-f1dc-4719-8d38-1c87ede48585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import BinaryLabelDataset \n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "def aif360_metric_object(num_of_instances, arr_grp, arr_true, arr_pred, seed=42):\n",
    "    \n",
    "    # synthetic feature data just to comply with AIF360 formatting to apply metric.\n",
    "    np.random.seed(seed)\n",
    "    features = pd.DataFrame({\n",
    "        'feature1': np.random.rand(num_of_instances),\n",
    "        'feature2': np.random.rand(num_of_instances),\n",
    "        'race': np.random.randint(0, 2, num_of_instances)  # placeholder protected attribute\n",
    "    })\n",
    "\n",
    "    features['race'] = arr_grp #protected attribute to represent the group membership array\n",
    "    \n",
    "    #these will be the variables to store the generated arrays with varying distributions \n",
    "    #these changing arrays will show the changing score of each metric being applied \n",
    "\n",
    "    data_true = features.copy() #dataframe with true labels\n",
    "    data_true['label'] = arr_true\n",
    "    \n",
    "    data_pred = features.copy() #dataframe with predicted labels\n",
    "    data_pred['label'] = arr_pred\n",
    "    \n",
    "    # Create BinaryLabelDataset objects for true and predicted datasets\n",
    "    dataset_true = BinaryLabelDataset(df=data_true, label_names=['label'], protected_attribute_names=['race'])\n",
    "    dataset_pred = BinaryLabelDataset(df=data_pred, label_names=['label'], protected_attribute_names=['race'])\n",
    "    \n",
    "    privileged_groups = [{'race': 1}]  # represents the majority group\n",
    "    unprivileged_groups = [{'race': 0}]  # represents the minority group\n",
    "    \n",
    "    metric = ClassificationMetric(dataset_true, dataset_pred, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "\n",
    "    return metric\n",
    "    \n",
    "#aif360_metric = aif360_metric_object(num_of_instances, arr_grp, arr_true, arr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e404f116-0696-4b1a-84c8-8066f95f8e5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'standard_custom_metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metrics_df\n\u001b[0;32m     57\u001b[0m num_of_instances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m---> 58\u001b[0m fixed_metrics_scores_table \u001b[38;5;241m=\u001b[39m automate_analysis(num_of_instances, randomise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     59\u001b[0m fixed_latex_table \u001b[38;5;241m=\u001b[39m fixed_metrics_scores_table\u001b[38;5;241m.\u001b[39mto_latex(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     61\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m#to display all 1000 rows of table.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[75], line 45\u001b[0m, in \u001b[0;36mautomate_analysis\u001b[1;34m(num_of_instances, randomise)\u001b[0m\n\u001b[0;32m     34\u001b[0m     eq_opp_diff \u001b[38;5;241m=\u001b[39m  aif360_metric\u001b[38;5;241m.\u001b[39mequal_opportunity_difference()\n\u001b[0;32m     35\u001b[0m     av_odds_diff \u001b[38;5;241m=\u001b[39m aif360_metric\u001b[38;5;241m.\u001b[39maverage_odds_difference()\n\u001b[0;32m     37\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrp_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m:grp_dist,\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m: true_dist,\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_dist\u001b[39m\u001b[38;5;124m\"\u001b[39m: pred_dist,\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrp_order\u001b[39m\u001b[38;5;124m\"\u001b[39m: grp_order,\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_order\u001b[39m\u001b[38;5;124m\"\u001b[39m: true_order,\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_order\u001b[39m\u001b[38;5;124m\"\u001b[39m: pred_order,\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced accuracy score\u001b[39m\u001b[38;5;124m\"\u001b[39m: balanced_accuracy_score,\n\u001b[1;32m---> 45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstandard_custom_metric score\u001b[39m\u001b[38;5;124m\"\u001b[39m: standard_custom_metric,                    \n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgei_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: gei_score,\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatistical_parity_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m:statistical_parity_diff,\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisparate_impact\u001b[39m\u001b[38;5;124m\"\u001b[39m: disparate_impact,\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meq_opp_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m:eq_opp_diff, \n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mav_odds_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m:av_odds_diff \n\u001b[0;32m     51\u001b[0m     })\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#create pandas dataframe from the results list\u001b[39;00m\n\u001b[0;32m     54\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'standard_custom_metric' is not defined"
     ]
    }
   ],
   "source": [
    "from aif360.datasets import BinaryLabelDataset \n",
    "from aif360.metrics import ClassificationMetric\n",
    "import itertools \n",
    "\n",
    "def automate_analysis(num_of_instances, randomise=False):\n",
    "  \n",
    "    dist_types = [\"50/50\", \"80/20\", \"90/10\", \"20/80\", \"10/90\"]\n",
    "    order_type = [\"asc\", \"desc\"] #for more variation of arrays\n",
    " \n",
    "    results = []\n",
    "\n",
    "    #number 43 and not convention number 42 because the latter gives a division by zero error\n",
    "    if randomise:\n",
    "        np.random.seed(43)\n",
    "\n",
    "    for (grp_dist, true_dist, pred_dist, grp_order, true_order, pred_order) in itertools.product(dist_types, dist_types, dist_types,\n",
    "                                                                                                order_type, order_type, order_type):\n",
    "        #generate array for current combination\n",
    "        arr_grp, arr_true, arr_pred = gen_fixed_dist_combinations(num_of_instances, \n",
    "                                                                  grp_dist=grp_dist, \n",
    "                                                                  true_dist=true_dist, \n",
    "                                                                  pred_dist=pred_dist, \n",
    "                                                                  grp_order=grp_order, \n",
    "                                                                  true_order=true_order, \n",
    "                                                                  pred_order=pred_order,\n",
    "                                                                  randomise=randomise)\n",
    "        balanced_accuracy_score = balanced_accuracy(arr_true, arr_pred)\n",
    "        var_custom_metric = var_new_metric(arr_grp, arr_true, arr_pred)\n",
    "        \n",
    "        aif360_metric = aif360_metric_object(num_of_instances, arr_grp, arr_true, arr_pred, seed=42)\n",
    "        gei_score = aif360_metric.generalized_entropy_index()\n",
    "        statistical_parity_diff = aif360_metric.mean_difference()\n",
    "        disparate_impact = aif360_metric.disparate_impact()\n",
    "        eq_opp_diff =  aif360_metric.equal_opportunity_difference()\n",
    "        av_odds_diff = aif360_metric.average_odds_difference()\n",
    "        \n",
    "        results.append({\n",
    "            \"grp_dist\":grp_dist,\n",
    "            \"true_dist\": true_dist,\n",
    "            \"pred_dist\": pred_dist,\n",
    "            \"grp_order\": grp_order,\n",
    "            \"true_order\": true_order,\n",
    "            \"pred_order\": pred_order,\n",
    "            \"balanced accuracy score\": balanced_accuracy_score,\n",
    "            \"variant_custom_metric score\": var_custom_metric,                    \n",
    "            \"gei_score\": gei_score,\n",
    "            \"statistical_parity_diff\":statistical_parity_diff,\n",
    "            \"disparate_impact\": disparate_impact,\n",
    "            \"eq_opp_diff\":eq_opp_diff, \n",
    "            \"av_odds_diff\":av_odds_diff \n",
    "        })\n",
    "\n",
    "    #create pandas dataframe from the results list\n",
    "    metrics_df = pd.DataFrame(results)\n",
    "    return metrics_df\n",
    "\n",
    "num_of_instances = 100\n",
    "fixed_metrics_scores_table = automate_analysis(num_of_instances, randomise=False)\n",
    "fixed_latex_table = fixed_metrics_scores_table.to_latex(index=False)\n",
    "\n",
    "pd.set_option('display.max_rows', None) #to display all 1000 rows of table.\n",
    "#print(fixed_metrics_scores_table)\n",
    "\n",
    "random_metrics_scores_table = automate_analysis(num_of_instances, randomise=True)\n",
    "random_latex_table = random_metrics_scores_table.to_latex(index=False)\n",
    "print(random_metrics_scores_table)\n",
    "#print(random_latex_table)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67029a02-8461-440f-a07d-997de27fc50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
