{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "20f72445-9bfa-4fd5-b2d8-57e79d6a61a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datasets\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.datasets import CompasDataset\n",
    "#import fairness metrics\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ce438faa-3cd1-48e9-98d6-a58088d4cb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Missing Data: 5 rows removed from CompasDataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "#load COMPAS dataset\n",
    "\n",
    "try:\n",
    "    compas = CompasDataset(\n",
    "        protected_attribute_names=['sex', 'race'],\n",
    "        privileged_classes=[['Female'], ['Caucasian']], \n",
    "        features_to_keep=['age', 'c_charge_degree', 'race', 'age_cat', \n",
    "                          'sex', 'priors_count', 'days_b_screening_arrest', 'c_charge_desc'],\n",
    "        features_to_drop=[],\n",
    "        categorical_features=['age_cat', 'c_charge_degree', 'c_charge_desc'],\n",
    "        label_name='two_year_recid'\n",
    "    )\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "\n",
    "    #returns the dataframe and the metadata in a tuple\n",
    "    df, meta = compas.convert_to_dataframe()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading COMPAS dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7dec9e86-adc1-46c5-b165-0c21fa7e9d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " group membership:  [1. 1. 0. ... 0. 0. 0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# copy dataset to ensure original remains unchanged\n",
    "df = df.copy()\n",
    "\n",
    "#separate features and labels\n",
    "features = ['race', 'sex', 'priors_count', 'c_charge_degree=F', 'c_charge_degree=M']\n",
    "target = 'two_year_recid' #binary target where 0 means does not offend, 1 means offends\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n",
    "\n",
    "X_test_indices = X_test.index\n",
    "\n",
    "#retrive each instance's group membership before scaling X_test to make predictions \n",
    "#scaling will make it lose the index information to retrieve this information\n",
    "grp_membership = df.loc[X_test_indices, 'race'].values\n",
    "print(\"\\n group membership: \", grp_membership, \"\\n\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "#predicted class labels 0 or 1\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81ef1ad8-6124-4c95-8029-c3602742a97f",
   "metadata": {},
   "source": [
    "#### Task 1: Three input arrays for new_metric function\n",
    "\n",
    "To do: Have three arrays each for predictions, ground truth labels, and group membership from the dataset and model.\n",
    "\n",
    "Important aspect of this part: indices of each array needs to align such that pred[0] refers to ground_truth[0] and grp_membership[0]. \n",
    "\n",
    "The arrays:\n",
    "1. predictions: positive and negative predictions from the classifier.\n",
    "2. ground_truth: this is the two_yr_recid column that represents the target variables. So, use y_test which contains ground truth values from the train_test_split for the dataset.\n",
    "3. grp_membership: array of group membership for each instance containing privileged (label 1 - Caucasian) and non-privileged (label 0 - not Caucasian) as defined by protected attribute of 'race'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "036a0032-6d6f-456b-b81a-1b6c78a24ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  [0. 0. 0. ... 0. 0. 0.]\n",
      "ground truth labels:  [0. 0. 1. ... 0. 1. 1.]\n",
      "group membership:  [1. 1. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#predictions array\n",
    "predictions = y_pred \n",
    "print(\"predictions: \", predictions)\n",
    "\n",
    "#ground truth labels array\n",
    "ground_truth = y_test.values \n",
    "print(\"ground truth labels: \", ground_truth)\n",
    "\n",
    "#group membership array defined above where model is trained.\n",
    "print(\"group membership: \", grp_membership)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4bb2b-1b23-4ed3-9bfa-58f4cf2639f5",
   "metadata": {},
   "source": [
    "#### Task 2: Coding the new metric using the three arrays as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bbdf0f1b-3780-4598-95c9-4f42e53e959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.26034063260340634, -0.26277372262773724, -0.25790754257907544)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_metric(arr_pred, arr_true, arr_grp): #varying these three for diff distri- protected groups can be diff sizes, edge cases 50 TP/50 TN, 10/90\n",
    "    #Two arrays for privileged and not privileged \n",
    "    #g1 and g2- contain predictions and trues are lists of lists [[], []]\n",
    "    grp_priv = [[], []]\n",
    "    grp_unpriv = [[], []]\n",
    "\n",
    "    #j is the number of unique groups in arr_grp - an implicit parameter.\n",
    "    j = len(set(arr_grp))\n",
    "    #print(\"total number of unique groups: \", j)\n",
    "\n",
    "    for i, label in enumerate(arr_grp):\n",
    "        #for privileged class\n",
    "        if label == 1.0:\n",
    "            #add the corresponding prediction + gt label for that class using the index associated with that label\n",
    "            grp_priv[0].append(arr_pred[i])\n",
    "            grp_priv[1].append(arr_true[i])\n",
    "        \n",
    "        #for unprivileged class \n",
    "        else:\n",
    "            grp_unpriv[0].append(arr_pred[i])\n",
    "            grp_unpriv[1].append(arr_true[i])\n",
    "    \n",
    "    #print(\"Privileged group: \", grp_priv)\n",
    "    #print(\"Unprivileged group: \", grp_unpriv)\n",
    "    \n",
    "    priv_indiv_bi = [] #stores individual benefit value of each instance\n",
    "    priv_grp_bi = 0 #tracks total benefit for group\n",
    "    \n",
    "    #1. for each index in a group calculate the benefit, bi\n",
    "    for pred, gt in zip(grp_priv[0], grp_priv[1]):\n",
    "        #calculate benefit for each instance in a group with new range, 0,1,-1 \n",
    "        #we remove '+1' to add variance? -- need to clarify how to verbalise this specific part\n",
    "        indiv_benefit = (int(pred) - int(gt)) \n",
    "        \n",
    "        #2. Sum the total benefit of each group\n",
    "        priv_grp_bi += indiv_benefit\n",
    "        \n",
    "        #3. divide by size of group which is total number of instances in each group.\n",
    "        priv_av_bi = priv_grp_bi / len(grp_priv[0]) #[0] has predictions which will give that number.\n",
    "\n",
    "        #store individual benefit of each instance in a list\n",
    "        priv_indiv_bi.append(indiv_benefit)\n",
    "        \n",
    "    #print(priv_indiv_bi)\n",
    "    #print(priv_grp_bi)\n",
    "    #print(priv_av_bi)\n",
    "    \n",
    "\n",
    "    unpriv_indiv_bi = []\n",
    "    unpriv_grp_bi = 0\n",
    "    for pred, gt in zip(grp_unpriv[0], grp_unpriv[1]):\n",
    "        indiv_benefit = (int(pred) - int(gt))  \n",
    "        unpriv_grp_bi += indiv_benefit\n",
    "        unpriv_av_bi = unpriv_grp_bi / len(grp_priv[0])\n",
    "        unpriv_indiv_bi.append(indiv_benefit)\n",
    "\n",
    "    #print(unpriv_indiv_bi)\n",
    "    #print(unpriv_grp_bi)\n",
    "    #print(unpriv_av_bi)\n",
    "   \n",
    "\n",
    "    #4. division result is divided by the sum of g1 and g2 - J\n",
    "    result = (priv_av_bi + unpriv_av_bi) / j\n",
    "\n",
    "    #print(\"new metric value: \", result)\n",
    "    return result, priv_av_bi, unpriv_av_bi\n",
    "\n",
    "new_metric(predictions, ground_truth, grp_membership)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
